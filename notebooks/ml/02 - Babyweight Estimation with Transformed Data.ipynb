{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source\n",
    "https://cloud.google.com/solutions/machine-learning/data-preprocessing-for-ml-with-tf-transform-pt2#introduction  \n",
    "https://github.com/GoogleCloudPlatform/tf-estimator-tutorials/blob/master/00_Miscellaneous/tf_transform/tft-02%20-%20Babyweight%20Estimation%20with%20Transformed%20Data.ipynb\n",
    "\n",
    "## Code adapted to TF2 partially based on  \n",
    "https://www.tensorflow.org/tfx/tutorials/transform/census  \n",
    "https://github.com/tensorflow/tfx/blob/master/docs/tutorials/transform/census.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Babyweight Estimation with Transformed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set global flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT ='mlteam-ml-specialization-2021' # change to your project_Id\n",
    "BUCKET = 'mlteam-ml-specialization-2021-taxi' # change to your bucket name\n",
    "REGION = 'europe-west1' # change to your region\n",
    "ROOT_DIR = 'babyweight_tft' # directory where the output is stored locally or on GCS\n",
    "\n",
    "RUN_LOCAL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['ROOT_DIR'] = ROOT_DIR\n",
    "os.environ['RUN_LOCAL'] = 'true' if RUN_LOCAL else 'false'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import data\n",
    "\n",
    "import tensorflow_transform as tft\n",
    "from tensorflow_transform.tf_metadata import dataset_metadata\n",
    "from tensorflow_transform.tf_metadata import dataset_schema\n",
    "\n",
    "from tensorflow_transform.tf_metadata import metadata_io\n",
    "from tensorflow_transform.beam.tft_beam_io import transform_fn_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow                     2.4.0\n",
      "tensorflow-cloud               0.1.13\n",
      "tensorflow-data-validation     0.28.0\n",
      "tensorflow-datasets            3.0.0\n",
      "tensorflow-estimator           2.4.0\n",
      "tensorflow-hub                 0.9.0\n",
      "tensorflow-io                  0.15.0\n",
      "tensorflow-metadata            0.28.0\n",
      "tensorflow-model-analysis      0.28.0\n",
      "tensorflow-probability         0.11.0\n",
      "tensorflow-serving-api         2.4.0\n",
      "tensorflow-transform           0.28.0\n",
      "apache-beam                    2.28.0\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep 'tensorflow'\n",
    "!pip list | grep 'beam'\n",
    "!pip list | grep 'cloud-dataflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = ROOT_DIR if RUN_LOCAL==True else \"gs://{}/{}\".format(BUCKET,ROOT_DIR)\n",
    "TRANSFORM_ARTEFACTS_DIR = os.path.join(OUTPUT_DIR,'transform')\n",
    "TRANSFORMED_DATA_DIR = os.path.join(OUTPUT_DIR,'transformed')\n",
    "TEMP_DIR = os.path.join(OUTPUT_DIR, 'tmp')\n",
    "MODELS_DIR = os.path.join(OUTPUT_DIR,'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature {\n",
       "  name: \"is_male_index\"\n",
       "  type: INT\n",
       "  int_domain {\n",
       "    min: -1\n",
       "    max: 1\n",
       "    is_categorical: true\n",
       "  }\n",
       "  presence {\n",
       "    min_fraction: 1.0\n",
       "  }\n",
       "  shape {\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  name: \"is_multiple_index\"\n",
       "  type: INT\n",
       "  int_domain {\n",
       "    min: -1\n",
       "    max: 1\n",
       "    is_categorical: true\n",
       "  }\n",
       "  presence {\n",
       "    min_fraction: 1.0\n",
       "  }\n",
       "  shape {\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  name: \"mother_age_bucketized\"\n",
       "  type: INT\n",
       "  int_domain {\n",
       "    min: 0\n",
       "    max: 4\n",
       "    is_categorical: true\n",
       "  }\n",
       "  presence {\n",
       "    min_fraction: 1.0\n",
       "  }\n",
       "  shape {\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  name: \"mother_age_log\"\n",
       "  type: FLOAT\n",
       "  presence {\n",
       "    min_fraction: 1.0\n",
       "  }\n",
       "  shape {\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  name: \"mother_age_normalized\"\n",
       "  type: FLOAT\n",
       "  presence {\n",
       "    min_fraction: 1.0\n",
       "  }\n",
       "  shape {\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  name: \"mother_race_index\"\n",
       "  type: INT\n",
       "  int_domain {\n",
       "    min: -1\n",
       "    max: 10\n",
       "    is_categorical: true\n",
       "  }\n",
       "  presence {\n",
       "    min_fraction: 1.0\n",
       "  }\n",
       "  shape {\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  name: \"weight_pounds\"\n",
       "  type: FLOAT\n",
       "  presence {\n",
       "    min_fraction: 1.0\n",
       "  }\n",
       "  shape {\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_metadata = metadata_io.read_metadata(\n",
    "        os.path.join(TRANSFORM_ARTEFACTS_DIR,\"transformed_metadata\"))\n",
    "\n",
    "TARGET_FEATURE_NAME = 'weight_pounds'\n",
    "\n",
    "transformed_metadata.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfrecords_input_fn(files_name_pattern, transformed_metadata,\n",
    "                       mode=tf.estimator.ModeKeys.EVAL,  \n",
    "                       num_epochs=1, \n",
    "                       batch_size=500):\n",
    "    \n",
    "    dataset = tf.data.experimental.make_batched_features_dataset(\n",
    "        file_pattern=files_name_pattern,\n",
    "        batch_size=batch_size,\n",
    "        features=tft.TFTransformOutput(TRANSFORM_ARTEFACTS_DIR).transformed_feature_spec(),\n",
    "        reader=tf.data.TFRecordDataset,\n",
    "        num_epochs=num_epochs,\n",
    "        shuffle=True if mode == tf.estimator.ModeKeys.TRAIN else False,\n",
    "        shuffle_buffer_size=1+(batch_size*2),\n",
    "        prefetch_buffer_size=1\n",
    "    )\n",
    "    \n",
    "    #iterator = dataset.make_one_shot_iterator()\n",
    "    features = tf.compat.v1.data.make_one_shot_iterator(dataset).get_next()\n",
    "    target = features.pop(TARGET_FEATURE_NAME)\n",
    "    return features, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_wide_and_deep_feature_columns(transformed_metadata, hparams):\n",
    "    types={\n",
    "        \"INT\":2,\n",
    "        \"FLOAT\":3\n",
    "    }\n",
    "    \n",
    "    deep_feature_columns = []\n",
    "    wide_feature_columns = []\n",
    "    \n",
    "    features = transformed_metadata.schema.feature\n",
    "    \n",
    "    for feature in features:\n",
    "        if feature.name == TARGET_FEATURE_NAME:\n",
    "            continue\n",
    "        \n",
    "        # creating numerical features\n",
    "        if feature.type == types[\"FLOAT\"]:\n",
    "            deep_feature_columns.append(tf.feature_column.numeric_column(feature.name))\n",
    "            \n",
    "        # creating categorical features with identity\n",
    "        elif feature.type == types[\"INT\"]:\n",
    "            if feature.int_domain.is_categorical:\n",
    "                wide_feature_columns.append(\n",
    "                    tf.feature_column.categorical_column_with_identity(\n",
    "                        feature.name, \n",
    "                        num_buckets=feature.int_domain.max+1)\n",
    "                )\n",
    "            else:\n",
    "                deep_feature_columns.append(tf.feature_column.numeric_column(feature.name)) \n",
    "     \n",
    "    if hparams.extend_feature_columns==True:\n",
    "        mother_race_X_mother_age_bucketized = tf.feature_column.crossed_column(\n",
    "            ['mother_age_bucketized', 'mother_race_index'],  55)\n",
    "        \n",
    "        wide_feature_columns.append(mother_race_X_mother_age_bucketized)\n",
    "        \n",
    "        mother_race_X_mother_age_bucketized_embedded = tf.feature_column.embedding_column(\n",
    "            mother_race_X_mother_age_bucketized, hparams.embed_dimension)\n",
    "        \n",
    "        deep_feature_columns.append(mother_race_X_mother_age_bucketized_embedded)\n",
    "    \n",
    "    print(\"Wide columns:\")\n",
    "    print(wide_feature_columns)\n",
    "    print(\"\")\n",
    "    print(\"Deep columns:\")\n",
    "    print(deep_feature_columns)\n",
    "    print(\"\")\n",
    "    \n",
    "    return wide_feature_columns, deep_feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_estimator(run_config, hparams):\n",
    "  \n",
    "    wide_feature_columns, deep_feature_columns = create_wide_and_deep_feature_columns(transformed_metadata, \n",
    "                                                                                      hparams)\n",
    "    print(f\"model will be saved to {run_config.model_dir}\")\n",
    "    estimator = tf.estimator.DNNLinearCombinedRegressor(\n",
    "                linear_feature_columns = wide_feature_columns,\n",
    "                dnn_feature_columns = deep_feature_columns,\n",
    "                dnn_hidden_units=hparams.hidden_units,\n",
    "                config = run_config,\n",
    "                model_dir = run_config.model_dir\n",
    "                )\n",
    "    \n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the old tf.contrib.training.HParams with EasyDict as a workaround\n",
    "class EasyDict(dict):\n",
    "    def __init__(self, *args, **kwargs): super().__init__(*args, **kwargs)\n",
    "    def __getattr__(self, name): return self[name]\n",
    "    def __setattr__(self, name, value): self[name] = value\n",
    "    def __delattr__(self, name): del self[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = EasyDict( #tf.contrib.training.HParams(\n",
    "    num_epochs=10,\n",
    "    batch_size=500,\n",
    "    hidden_units=[32, 16],\n",
    "    max_steps=100,\n",
    "    embed_dimension=5,\n",
    "    extend_feature_columns=False,\n",
    "    evaluate_after_sec=10\n",
    ")\n",
    "\n",
    "model_dir = os.path.join(MODELS_DIR,\"dnn_estimator\")\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    tf_random_seed=19830610,\n",
    "    model_dir=model_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_files = os.path.join(TRANSFORMED_DATA_DIR, \"train-*.tfrecords\")\n",
    "eval_data_files = os.path.join(TRANSFORMED_DATA_DIR, \"eval-*.tfrecords\")\n",
    "\n",
    "# TrainSpec\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "  input_fn = lambda: tfrecords_input_fn(train_data_files,transformed_metadata,\n",
    "    mode=tf.estimator.ModeKeys.TRAIN,\n",
    "    num_epochs= hparams.num_epochs,\n",
    "    batch_size = hparams.batch_size\n",
    "  ),\n",
    "  max_steps=hparams.max_steps,\n",
    ")\n",
    "\n",
    "# EvalSpec\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "  input_fn =lambda: tfrecords_input_fn(eval_data_files,transformed_metadata),\n",
    "  steps = None,\n",
    "  throttle_secs = hparams.evaluate_after_sec # evalute after each 10 training seconds!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wide columns:\n",
      "[IdentityCategoricalColumn(key='is_male_index', number_buckets=2, default_value=None), IdentityCategoricalColumn(key='is_multiple_index', number_buckets=2, default_value=None), IdentityCategoricalColumn(key='mother_age_bucketized', number_buckets=5, default_value=None), IdentityCategoricalColumn(key='mother_race_index', number_buckets=11, default_value=None)]\n",
      "\n",
      "Deep columns:\n",
      "[NumericColumn(key='mother_age_log', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='mother_age_normalized', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n",
      "\n",
      "model will be saved to gs://mlteam-ml-specialization-2021-taxi/babyweight_tft/models/dnn_estimator\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'gs://mlteam-ml-specialization-2021-taxi/babyweight_tft/models/dnn_estimator', '_tf_random_seed': 19830610, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "\n",
      "Experiment started at 14:22:15\n",
      ".......................................\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/adagrad.py:83: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into gs://mlteam-ml-specialization-2021-taxi/babyweight_tft/models/dnn_estimator/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 58.640434, step = 0\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 100...\n",
      "INFO:tensorflow:Saving checkpoints for 100 into gs://mlteam-ml-specialization-2021-taxi/babyweight_tft/models/dnn_estimator/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 100...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-04-08T14:22:26Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from gs://mlteam-ml-specialization-2021-taxi/babyweight_tft/models/dnn_estimator/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 1.06340s\n",
      "INFO:tensorflow:Finished evaluation at 2021-04-08-14:22:27\n",
      "INFO:tensorflow:Saving dict for global step 100: average_loss = 46.66902, global_step = 100, label/mean = 7.268033, loss = 46.669025, prediction/mean = 0.5612795\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: gs://mlteam-ml-specialization-2021-taxi/babyweight_tft/models/dnn_estimator/model.ckpt-100\n",
      "INFO:tensorflow:Loss for final step: 47.23433.\n",
      ".......................................\n",
      "Experiment finished at 14:22:28\n",
      "\n",
      "Experiment elapsed time: 13.786089 seconds\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "if tf.io.gfile.exists(model_dir):\n",
    "    tf.io.gfile.rmtree(model_dir)\n",
    "\n",
    "estimator = create_estimator(run_config, hparams)\n",
    "\n",
    "time_start = datetime.utcnow() \n",
    "print(\"\")\n",
    "print(\"Experiment started at {}\".format(time_start.strftime(\"%H:%M:%S\")))\n",
    "print(\".......................................\") \n",
    "\n",
    "\n",
    "tf.estimator.train_and_evaluate(\n",
    "  estimator,\n",
    "  train_spec,\n",
    "  eval_spec\n",
    ")\n",
    "\n",
    "\n",
    "time_end = datetime.utcnow() \n",
    "print(\".......................................\")\n",
    "print(\"Experiment finished at {}\".format(time_end.strftime(\"%H:%M:%S\")))\n",
    "print(\"\")\n",
    "time_elapsed = time_end - time_start\n",
    "print(\"Experiment elapsed time: {} seconds\".format(time_elapsed.total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"is_male_index\"\n",
       "type: INT\n",
       "int_domain {\n",
       "  min: -1\n",
       "  max: 1\n",
       "  is_categorical: true\n",
       "}\n",
       "presence {\n",
       "  min_fraction: 1.0\n",
       "}\n",
       "shape {\n",
       "}\n",
       ", name: \"is_multiple_index\"\n",
       "type: INT\n",
       "int_domain {\n",
       "  min: -1\n",
       "  max: 1\n",
       "  is_categorical: true\n",
       "}\n",
       "presence {\n",
       "  min_fraction: 1.0\n",
       "}\n",
       "shape {\n",
       "}\n",
       ", name: \"mother_age_bucketized\"\n",
       "type: INT\n",
       "int_domain {\n",
       "  min: 0\n",
       "  max: 4\n",
       "  is_categorical: true\n",
       "}\n",
       "presence {\n",
       "  min_fraction: 1.0\n",
       "}\n",
       "shape {\n",
       "}\n",
       ", name: \"mother_age_log\"\n",
       "type: FLOAT\n",
       "presence {\n",
       "  min_fraction: 1.0\n",
       "}\n",
       "shape {\n",
       "}\n",
       ", name: \"mother_age_normalized\"\n",
       "type: FLOAT\n",
       "presence {\n",
       "  min_fraction: 1.0\n",
       "}\n",
       "shape {\n",
       "}\n",
       ", name: \"mother_race_index\"\n",
       "type: INT\n",
       "int_domain {\n",
       "  min: -1\n",
       "  max: 10\n",
       "  is_categorical: true\n",
       "}\n",
       "presence {\n",
       "  min_fraction: 1.0\n",
       "}\n",
       "shape {\n",
       "}\n",
       ", name: \"weight_pounds\"\n",
       "type: FLOAT\n",
       "presence {\n",
       "  min_fraction: 1.0\n",
       "}\n",
       "shape {\n",
       "}\n",
       "]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_metadata.schema.feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_FEATURE_NAMES = ['is_male', 'mother_race']\n",
    "NUMERIC_FEATURE_NAMES = ['mother_age', 'plurality', 'gestation_weeks']\n",
    "TARGET_FEATURE_NAME = 'weight_pounds'\n",
    "KEY_COLUMN = 'key'\n",
    "\n",
    "def create_placeholders():\n",
    "    return dict(\n",
    "        [(name, tf.keras.Input((), dtype=tf.string, name=name))\n",
    "         for name in CATEGORICAL_FEATURE_NAMES] +\n",
    "        [(name, tf.keras.Input((), dtype=tf.float32, name=name))\n",
    "         for name in NUMERIC_FEATURE_NAMES]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Estimator to SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_2:0\\022\\013mother_race\"\n",
      "\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_4:0\\022\\007is_male\"\n",
      "\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_6:0\\022\\013is_multiple\"\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_transform/tf_utils.py:266: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py:1482: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  run_metadata_ptr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Regression input must be a single string Tensor; got {'is_male': <tf.Tensor 'is_male:0' shape=(None,) dtype=string>, 'mother_race': <tf.Tensor 'mother_race:0' shape=(None,) dtype=string>, 'mother_age': <tf.Tensor 'mother_age:0' shape=(None,) dtype=float32>, 'plurality': <tf.Tensor 'plurality:0' shape=(None,) dtype=float32>, 'gestation_weeks': <tf.Tensor 'gestation_weeks:0' shape=(None,) dtype=float32>}\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'is_male': <tf.Tensor 'is_male:0' shape=(None,) dtype=string>, 'mother_race': <tf.Tensor 'mother_race:0' shape=(None,) dtype=string>, 'mother_age': <tf.Tensor 'mother_age:0' shape=(None,) dtype=float32>, 'plurality': <tf.Tensor 'plurality:0' shape=(None,) dtype=float32>, 'gestation_weeks': <tf.Tensor 'gestation_weeks:0' shape=(None,) dtype=float32>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from gs://mlteam-ml-specialization-2021-taxi/babyweight_tft/models/dnn_estimator/model.ckpt-100\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:Assets written to: gs://mlteam-ml-specialization-2021-taxi/babyweight_tft/models/dnn_estimator/export/temp-1617891749/assets\n",
      "INFO:tensorflow:SavedModel written to: gs://mlteam-ml-specialization-2021-taxi/babyweight_tft/models/dnn_estimator/export/temp-1617891749/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "def serving_input_receiver_fn():\n",
    "    tf_transform_output = tft.TFTransformOutput(TRANSFORM_ARTEFACTS_DIR)\n",
    "    def serving_input_fn():\n",
    "        raw_input_features = create_placeholders()\n",
    "        transformed_features = tf_transform_output.transform_raw_features(\n",
    "            raw_input_features, drop_unused_features=True)\n",
    "        return tf.estimator.export.ServingInputReceiver(\n",
    "            transformed_features, raw_input_features)\n",
    "    return serving_input_fn\n",
    "\n",
    "    \n",
    "export_dir = os.path.join(model_dir, 'export')\n",
    "\n",
    "if tf.io.gfile.exists(export_dir):\n",
    "    tf.io.gfile.rmtree(export_dir)\n",
    "        \n",
    "estimator.export_saved_model(\n",
    "    export_dir_base=export_dir,\n",
    "    serving_input_receiver_fn=serving_input_receiver_fn()\n",
    ")\n",
    "\n",
    "os.environ['export_dir'] = export_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the Exported Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mlteam-ml-specialization-2021-taxi/babyweight_tft/models/dnn_estimator/export/1617891749/\n",
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['predict']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['gestation_weeks'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: gestation_weeks:0\n",
      "    inputs['is_male'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: is_male:0\n",
      "    inputs['mother_age'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: mother_age:0\n",
      "    inputs['mother_race'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: mother_race:0\n",
      "    inputs['plurality'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: plurality:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['predictions'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 1)\n",
      "        name: add:0\n",
      "  Method name is: tensorflow/serving/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-08 14:22:37.354645: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "if [ ${RUN_LOCAL} ]\n",
    "then \n",
    "saved_model_dir=$(gsutil ls ${export_dir} | tail -n 1)\n",
    "else\n",
    "saved_model_dir=${export_dir}/$(ls ${export_dir} | tail -n 1)\n",
    "fi\n",
    "\n",
    "echo $saved_model_dir\n",
    "saved_model_cli show --dir=${saved_model_dir} --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Exported Model for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.5084222]], dtype=float32)>}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_dir=os.path.join(export_dir, tf.io.gfile.listdir(export_dir)[0])\n",
    "model = tf.saved_model.load(saved_model_dir)\n",
    "predictor_fn = model.signatures[\"predict\"]\n",
    "predictor_fn(\n",
    "    is_male=tf.constant(['True']),\n",
    "    mother_age=tf.constant([26.0]),\n",
    "    mother_race=tf.constant(['Asian Indian']),\n",
    "    plurality=tf.constant([1.0]),\n",
    "    gestation_weeks=tf.constant([39.0]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.5084222]], dtype=float32)>}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance = {\n",
    "        'is_male': 'True',\n",
    "        'mother_age': 26.0,\n",
    "        'mother_race': 'Asian Indian',\n",
    "        'plurality': 1.0,\n",
    "        'gestation_weeks': 39.0\n",
    "}\n",
    "\n",
    "feed=dict((k, tf.constant([v])) for k, v in instance.items())\n",
    "predictor_fn(**feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
